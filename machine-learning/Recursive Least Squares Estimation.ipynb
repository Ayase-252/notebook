{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Least Squares Estimation\n",
    "\n",
    "## Reference\n",
    "[1] L. Ljung, System Identification Theory for the User\n",
    "\n",
    "## 1 Linear Regressions and Least Squares\n",
    "### 1.1 Autoregressive-moving-average Model\n",
    "考虑自回归滑动平均模型（ARMA），\n",
    "\n",
    "### 1.2 Least-squares Criterion\n",
    "\n",
    "为了得到$\\theta$，我们首先需要一个判断准则去评定$\\theta$的好坏。自然的，我们会关心模型输出与实际输出的差。所以定义误差为：\n",
    "\n",
    "\\begin{equation}\n",
    "\\epsilon(t,\\theta)=y(t)-\\phi^T(t)\\theta\n",
    "\\end{equation}\n",
    "\n",
    "为后续计算的方便，取\n",
    "\n",
    "$$V_N(\\theta,Z^N)=\\frac{1}{2N}\\sum_{t=1}^N[\\epsilon]^2$$\n",
    "\n",
    "为指标函数。上式$V_N$对$\\theta$求偏导数，并使用$\\phi\\phi^T\\theta=\\phi y$，可以得出对$\\theta$的最小二乘估计$\\hat{\\theta}$。\n",
    "\n",
    "$$\\hat{\\theta}=\\arg_\\theta\\min V_N(\\theta,Z^N)=[\\frac{1}{N}\\sum_{t=1}^N\\phi(t)\\phi^T(t)]^{-1}\\frac{1}{N}\\sum_{t=1}^N\\phi(t)y(t)$$\n",
    "\n",
    "*注意：这里处理的是SISO情形，即$y(t),u(t)$均是标量。*\n",
    "\n",
    "定义：\n",
    "\n",
    "$$R(N)=\\frac{1}{N}\\sum_{t=1}^N\\phi(t)\\phi^T(t)\\in R^{d\\times d}$$\n",
    "\n",
    "$$f(N)=\\frac{1}{N}\\sum_{t=1}^N\\phi(t)y(t)\\in R^d$$\n",
    "\n",
    "\n",
    "### 1.3 Weighted Least-Squares Estimation(WLS)\n",
    "\n",
    "如果系统参数时变较快，对过去的输入-输出的拟合意义不大。所以在指标函数中引入权重，衰减过去数据的影响。\n",
    "\n",
    "修改指标函数为：\n",
    "\n",
    "$$V_N(\\theta,Z^N)=\\frac{1}{2N}\\sum_{t=1}^N[\\alpha_i\\epsilon]^2$$(权重固定)\n",
    "\n",
    "或\n",
    "\n",
    "$$V_N(\\theta,Z^N)=\\frac{1}{2N}\\sum_{t=1}^N[\\beta(N,t)\\epsilon]^2$$（权重时变）\n",
    "\n",
    "## 2 Recursive Least-Squares Algorithm\n",
    "\n",
    "### 2.1 Prototype of RLS\n",
    "\n",
    "采用带有权重的最小二乘准则：\n",
    "\n",
    "$$\\hat{\\theta_t}=\\arg_\\theta\\min\\sum_{k=1}^{t}\\beta(t,k)[y(k)-\\phi^T(k)\\theta]^2$$\n",
    "\n",
    "可以得到最优估计为：\n",
    "\n",
    "$$\\hat{\\theta_t}=\\bar{R}^{-1}(t)f(t)$$\n",
    "\n",
    "其中：\n",
    "\n",
    "$$\\bar{R}(t)=\\sum_{k=1}^t\\beta(t,k)\\phi(k)\\phi^T(k)$$\n",
    "\n",
    "$$f(t)=\\sum_{k=1}^t\\beta(t,k)\\phi(k)y(k)$$\n",
    "\n",
    "设权重序列满足：\n",
    "\n",
    "$$\\beta(t,k)=\\lambda(t)\\beta(t-1,k)$$\n",
    "\n",
    "$$\\beta(t,t)=1$$\n",
    "\n",
    "即：\n",
    "\n",
    "$$\\beta(t,k)=\\prod_{j=k+1}^t\\lambda(t)$$\n",
    "\n",
    "*注意：这里处理一种特殊的权重序列。*\n",
    "\n",
    "在上述权重序列的影响下，回顾$\\bar{R}(t),f(t)$的定义式，$\\bar{R}(t),f(t)$满足关系：\n",
    "\n",
    "$$\\bar{R}(t)=\\lambda(t)\\bar{R}(t-1)+\\phi(t)\\phi^T(t)$$\n",
    "\n",
    "$$f(t)=\\lambda(t)f(t-1)+\\phi(t)y(t)$$\n",
    "\n",
    "将上述关系带入$\\hat{\\theta}_t$的估计式中：\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{\\theta}_t & = \\bar{R}(t)^{-1}f(t) \\\\\n",
    "& = \\bar{R}(t)^{-1}[\\lambda(t)f(t-1)+\\phi(t)y(t)] \\\\\n",
    "& = \\bar{R}(t)^{-1}[\\lambda(t)\\bar{R}(t-1)\\hat{\\theta}_{t-1}+\\phi(t)y(t)] \\\\\n",
    "& = \\bar{R}(t)^{-1}[\\lambda(t)(\\bar{R}(t)-\\phi(t)\\phi^T(t))\\hat{\\theta}_{t-1}+\\phi(t)y(t)] \\\\\n",
    "& = \\hat{\\theta}_{t-1} + \\bar{R}^{-1}(t)\\phi(t)[y(t)-\\phi^T(t)\\hat{\\theta}_{t-1}]\n",
    "\\end{align}\n",
    "\n",
    "这样我们就得到了**RLS的两个递推式**：\n",
    "\n",
    "\\begin{eqnarray}\n",
    "& \\hat{\\theta}_t & = \\hat{\\theta}_{t-1} + \\bar{R}^{-1}(t)\\phi(t)[y(t)-\\phi^T(t)\\hat{\\theta}_{t-1}] \\\\\n",
    "& \\bar{R}(t) & = \\lambda(t)\\bar{R}(t-1)+\\phi(t)\\phi^T(t)\n",
    "\\end{eqnarray}\n",
    "\n",
    "上式要求计算矩阵的逆，在计算机中计算复杂度较高。所以需要尝试将求逆的操作转化为一个计算较为简便的操作。\n",
    "\n",
    "引入定理：\n",
    "\n",
    "$$\\exists A,B,C,D:P=A+BCD \\rightarrow P^{-1}=[A+BCD]^{-1}=A^{-1}-A^{-1}B[DA^{-1}B+C^{-1}]^{-1}DA^{-1}$$\n",
    "\n",
    "其中$A,B,C,D,P$均为适当维矩阵。\n",
    "\n",
    "令$P(t)=\\bar{R}^{-1}(t)$，使用关系式凑上述定理的形式，则有$A=\\lambda(t)\\bar{R}(t-1), B=\\phi(t), C=I, D=\\phi^T(t)$，\n",
    "则\n",
    "\n",
    "\\begin{align}\n",
    "P(t) &= A^{-1}-A^{-1}B[DA^{-1}B+C^{-1}]^{-1}DA^{-1} \\\\\n",
    "    &= \\frac{1}{\\lambda(t)}[P(t-1)-\\frac{P(t-1)\\phi(t)\\phi^T(t)P(t-1)}{\\lambda(t)+\\phi^T(t)P(t-1)\\phi(t)}]\n",
    "\\end{align}\n",
    "\n",
    "上面的迭代式还可以再进行简化，考虑$P(t)\\phi(t)$：\n",
    "\n",
    "\\begin{align}\n",
    "P(t)\\phi(t) &= \\frac{1}{\\lambda(t)}P(t-1)\\phi(t)-\\frac{1}{\\lambda(t)}\\frac{P(t-1)\\phi(t)\\phi^T(t)P(t-1)\\phi(t)}{\\lambda(t)+\\phi^T(t)P(t-1)\\phi(t)} \\\\\n",
    "    &=\\frac{P(t-1)\\phi(t)}{\\lambda(t)+\\phi^T(t)P(t-1)\\phi(t)}\n",
    "\\end{align}\n",
    "\n",
    "利用上述结果，令$L(t)=P(t)\\phi(t)$，我们就获得了带权重的RLS估计算法（也可以称带遗忘因子的RLS估计算法）：\n",
    "\n",
    ">带权重的RLS估计算法：\n",
    "\\begin{eqnarray}\n",
    "& L(t) &= \\frac{P(t-1)\\phi(t)}{\\lambda(t)+\\phi^T(t)P(t-1)\\phi(t)} \\\\\n",
    "& \\hat{\\theta}_t & = \\hat{\\theta}_{t-1} + L(t)[y(t)-\\phi^T(t)\\hat{\\theta}_{t-1}] \\\\\n",
    "& P(t) &= \\frac{1}{\\lambda(t)}[P(t-1)-L(t)\\phi^T(t)P(t-1)] \\\\\n",
    "\\end{eqnarray}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
